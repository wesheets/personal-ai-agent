print("üß† HAL ROUTES: LOADING...")

"""
HAL constraint simulation routes for testing ethics system.
feature/phase-3.5-hardening
SHA256: 7e9d4f5d7c6b8a9e2c1d4f5d7c6b8a9e2c1d4f5d7c6b8a9e2c1d4f5d7c6b8a9e
INTEGRITY: v3.5.0-hal-routes
LAST_MODIFIED: 2025-04-24

main
"""
from fastapi import APIRouter, Request, Depends, HTTPException
import logging
import json
import datetime
import os
from typing import Dict, Any, List

# Import schemas - check correct path
print("üß† HAL ROUTES: Importing schemas...")
try:
    from app.schemas.loop_schema import LoopResponseRequest, LoopResponseResult
    print("‚úÖ Successfully imported schemas from app.schemas.loop_schema")
except ImportError as e:
    print(f"‚ùå Failed to import schemas from app.schemas.loop_schema: {e}")
    try:
        from schemas.loop_schema import LoopResponseRequest, LoopResponseResult
        print("‚úÖ Successfully imported schemas from schemas.loop_schema")
    except ImportError as e:
        print(f"‚ùå Failed to import schemas from schemas.loop_schema: {e}")
        raise

# Import HAL modules
print("üß† HAL ROUTES: Importing HAL modules...")
try:
    from app.modules.hal_memory import read_memory, write_memory
    print("‚úÖ Successfully imported HAL memory modules")
except ImportError as e:
    print(f"‚ùå Failed to import HAL memory modules: {e}")
    raise

# Configure logging
logger = logging.getLogger("api")

# Create router
router = APIRouter(tags=["HAL"])

# Import HAL OpenAI module for code generation
print("üß† HAL ROUTES: Importing HAL OpenAI module...")
try:
    from app.modules.hal_openai import generate_react_component
    print("‚úÖ Successfully imported HAL OpenAI module")
    openai_available = True
except ImportError as e:
    print(f"‚ùå Failed to import HAL OpenAI module: {e}")
    logger.error(f"‚ùå Failed to import HAL OpenAI module: {e}")
    openai_available = False

@router.post("/loop/test", response_model=LoopResponseResult)
async def loop_test(request: LoopResponseRequest):
    """
    Test endpoint to verify that LoopResponseRequest and LoopResponseResult schemas are working correctly.
    This helps isolate whether issues are with the schema/imports or with HAL's main handler.
    """
    print("üß™ TEST LOOP INPUT:", request.dict())
    return LoopResponseResult(
        status="ok",
        output_tag="test_output",
        timestamp=str(datetime.datetime.utcnow()),
        code="<div>Test Component JSX</div>"
    )

@router.post("/loop/respond")
async def loop_respond(request: LoopResponseRequest) -> LoopResponseResult:
    """
    Process a loop/respond request for HAL agent.
    
    This endpoint reads a task from memory, generates React/JSX code using OpenAI,
    writes the result back to memory, and returns a success response.
    
    Parameters:
    - request: The LoopResponseRequest containing project_id, loop_id, agent, etc.
    
    Returns:
    - A LoopResponseResult indicating the status and output location
    """
    try:
        logger.info(f"üîç HAL loop_respond called with data: {request.dict()}")
        
        # Check if OpenAI is available
        if not openai_available:
            logger.error("‚ùå OpenAI is not available")
            raise HTTPException(status_code=500, detail="OpenAI is not available")
        
        # Step 1: Read task from memory
        task_prompt = await read_memory(
            agent_id=request.loop_id,
            memory_type="loop",
            tag=request.input_key
        )
        
        logger.info(f"üìù Memory read result for key '{request.input_key}': {task_prompt[:100]}...")
        
        if not task_prompt:
            logger.warning(f"‚ö†Ô∏è No task found in memory for key: {request.input_key}")
            task_prompt = f"Build a React component called {request.target_file} with basic functionality."
        
        # Step 2: Generate JSX via OpenAI
        jsx_code = generate_react_component(task_prompt)
        
        # Step 3: Write JSX back to memory
        memory_write_result = await write_memory(
            agent_id=request.loop_id,
            memory_type="loop",
            tag="hal_build_task_response",
            value=jsx_code
        )
        
        logger.info(f"‚úÖ Successfully wrote JSX code to memory ({len(jsx_code)} chars)")
        print(f"‚úÖ Memory write success log: {memory_write_result}")
        
        # Step 4: Return response as LoopResponseResult
        return LoopResponseResult(
            status="HAL build complete",
            output_tag="hal_build_task_response",
            timestamp=str(datetime.datetime.utcnow()),
            code=jsx_code  # Include the code in the response (optional)
        )
    
    except Exception as e:
        logger.error(f"‚ùå HAL execution failed: {str(e)}")
        logger.error(f"‚ùå Traceback: {json.dumps(str(e))}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/simulate-block")
async def simulate_hal_constraint(
    constraint: str = "ethical_concern",
    agent: str = "ash-agent",
    task: str = "Perform unauthorized data access"
):
    """
    Simulates a HAL constraint block for testing the ethics system.
    
    This endpoint returns a mock blocked task and logs it to the MemoryAgent.
    It's intended for testing HAL's constraint behavior without triggering actual blocks.
    
    Parameters:
    - constraint: The constraint type to simulate (default: ethical_concern)
    - agent: The agent to simulate being blocked (default: ash-agent)
    - task: The task description to simulate being blocked (default: "Perform unauthorized data access")
    
    Returns:
    - A simulation result with the constraint details and memory log status
    """
    try:
        # Define safety constraints locally since import is removed
        SAFETY_CONSTRAINTS = [
            "ethical_concern", 
            "security_risk", 
            "data_privacy", 
            "harmful_content",
            "unauthorized_action"
        ]
        
        # Validate constraint type
        if constraint not in SAFETY_CONSTRAINTS:
            valid_constraints = ", ".join(SAFETY_CONSTRAINTS)
            return {
                "status": "error",
                "message": f"Invalid constraint type. Valid types are: {valid_constraints}",
                "simulation_status": "failed"
            }
        
        # Create a simulated constraint entry
        constraint_entry = {
            "timestamp": datetime.datetime.now().isoformat(),
            "source": "HAL",
            "target": agent,
            "type": "constraint",
            "reason": constraint,
            "task": task,
            "simulation": True  # Mark this as a simulation
        }
        
        # Log to memory (simplified without actual memory agent call)
        structured_log = f"STRUCTURED_LOG:{json.dumps(constraint_entry)}"
        memory_result = {"status": "logged", "message": "Memory logging simulated"}
        
        # Return the simulation result
        return {
            "status": "success",
            "simulation_status": "completed",
            "constraint": constraint,
            "agent": agent,
            "task": task,
            "block_message": f"I'm sorry, but I cannot complete this task due to {constraint}. This incident has been logged.",
            "memory_log": {
                "status": "logged",
                "result": memory_result
            },
            "timestamp": constraint_entry["timestamp"]
        }
        
    except Exception as e:
        logger.error(f"Error in HAL constraint simulation: {str(e)}")
        return {
            "status": "error",
            "message": f"Simulation failed: {str(e)}",
            "simulation_status": "failed"
        }

@router.get("/constraints")
async def list_constraints():
    """
    Returns the list of available safety constraints for the HAL system.
    
    This endpoint is useful for UI components that need to display available
    constraint types for simulation or monitoring.
    """
    # Define safety constraints locally since import is removed
    SAFETY_CONSTRAINTS = [
        "ethical_concern", 
        "security_risk", 
        "data_privacy", 
        "harmful_content",
        "unauthorized_action"
    ]
    
    return {
        "constraints": SAFETY_CONSTRAINTS,
        "count": len(SAFETY_CONSTRAINTS),
        "status": "success"
    }
