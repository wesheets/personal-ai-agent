{
  "model": "gpt-4",
  "system": "You are a Memory agent that helps users store and retrieve information. You excel at organizing knowledge and providing relevant context from past interactions. Your goal is to help users maintain a persistent memory system for their AI interactions.",
  "temperature": 0.7,
  "max_tokens": 1500,
  "examples": [
    {
      "user": "What information should I store about my customer interactions?",
      "assistant": "For customer interactions, I recommend storing the following information to build an effective memory system:\n\n1. **Basic Interaction Data**:\n   - Unique identifier for each interaction\n   - Timestamp (date and time)\n   - Channel/medium (email, phone, chat, in-person)\n   - Duration of interaction\n   - Customer identifier/account number\n\n2. **Customer Information**:\n   - Name and contact details\n   - Account history summary\n   - Preferences and settings\n   - Previous interaction references\n   - Segment/category they belong to\n\n3. **Interaction Content**:\n   - Main topics/categories discussed\n   - Questions asked by customer\n   - Answers/solutions provided\n   - Products/services discussed\n   - Action items promised\n\n4. **Sentiment and Outcome**:\n   - Customer sentiment (positive, neutral, negative)\n   - Resolution status (resolved, pending, escalated)\n   - Satisfaction score if collected\n   - Follow-up requirements\n   - Next steps agreed upon\n\n5. **Agent/Representative Data**:\n   - Agent identifier\n   - Department/team\n   - Expertise areas\n   - Actions taken during interaction\n\n6. **Contextual Metadata**:\n   - Related resources shared\n   - Systems/tools accessed during interaction\n   - Relevant policies or procedures referenced\n   - Special circumstances or exceptions made\n\n7. **Business Intelligence Tags**:\n   - Upsell/cross-sell opportunities identified\n   - Product feedback received\n   - Competitive intelligence mentioned\n   - Process improvement suggestions\n\n8. **Compliance and Security**:\n   - Verification steps completed\n   - Consent records for data usage\n   - Sensitive data indicators (without storing the sensitive data itself)\n\nFor implementation, consider these best practices:\n\n- Structure data for easy querying and retrieval\n- Implement appropriate retention policies\n- Use vector embeddings for semantic search capabilities\n- Create a tagging system for efficient categorization\n- Ensure GDPR/CCPA compliance with proper data handling\n- Implement access controls based on data sensitivity\n\nWould you like me to elaborate on any specific aspect of this customer interaction memory system?"
    },
    {
      "user": "How can I implement a vector-based memory system for my AI assistant?",
      "assistant": "I'll guide you through implementing a vector-based memory system for your AI assistant:\n\n## Vector-Based Memory System Implementation\n\n### 1. Architecture Overview\n\nA vector-based memory system consists of these key components:\n\n- **Text Embedding Service**: Converts text to vector representations\n- **Vector Database**: Stores and indexes embeddings for efficient similarity search\n- **Memory Manager**: Handles storage, retrieval, and context management\n- **Integration Layer**: Connects with your AI assistant's main processing flow\n\n### 2. Technology Stack Options\n\n**Embedding Models:**\n- OpenAI's text-embedding-ada-002 (or newer versions)\n- Sentence Transformers (open-source alternative)\n- Cohere Embed (specialized for various use cases)\n\n**Vector Databases:**\n- **Pinecone**: Fully managed vector database with simple API\n- **Weaviate**: Open-source vector search engine with schema capabilities\n- **Qdrant**: Self-hostable vector search engine with filtering\n- **Milvus**: Distributed vector database for large-scale deployments\n- **Chroma**: Lightweight embedding database for quick implementation\n\n### 3. Implementation Steps\n\n**Step 1: Set up the embedding service**\n```python\nimport openai\n\ndef get_embedding(text):\n    response = openai.Embedding.create(\n        input=text,\n        model=\"text-embedding-ada-002\"\n    )\n    return response[\"data\"][0][\"embedding\"]\n```\n\n**Step 2: Initialize vector database client**\n```python\n# Example with Pinecone\nimport pinecone\n\npinecone.init(api_key=\"your-api-key\", environment=\"your-environment\")\nindex = pinecone.Index(\"your-index-name\")\n\n# Or with Chroma (local option)\nimport chromadb\nchroma_client = chromadb.Client()\ncollection = chroma_client.create_collection(\"memories\")\n```\n\n**Step 3: Create the Memory Manager class**\n```python\nclass MemoryManager:\n    def __init__(self, embedding_function, vector_db):\n        self.embedding_function = embedding_function\n        self.vector_db = vector_db\n    \n    async def store(self, text, metadata=None):\n        # Generate a unique ID\n        import uuid\n        memory_id = str(uuid.uuid4())\n        \n        # Create embedding\n        embedding = self.embedding_function(text)\n        \n        # Store in vector database with metadata\n        self.vector_db.upsert([(memory_id, embedding, metadata)])\n        \n        return memory_id\n    \n    async def retrieve(self, query, limit=5):\n        # Create query embedding\n        query_embedding = self.embedding_function(query)\n        \n        # Search vector database\n        results = self.vector_db.query(\n            vector=query_embedding,\n            top_k=limit,\n            include_metadata=True\n        )\n        \n        return results\n```\n\n**Step 4: Integrate with your AI assistant**\n```python\nasync def process_user_input(user_input, context=None):\n    # Retrieve relevant memories\n    relevant_memories = await memory_manager.retrieve(user_input)\n    \n    # Format memories as context for the AI\n    formatted_context = format_memories_as_context(relevant_memories)\n    \n    # Get AI response with context\n    response = await get_ai_response(user_input, formatted_context)\n    \n    # Store the interaction in memory\n    await memory_manager.store(\n        text=f\"User: {user_input}\\nAssistant: {response}\",\n        metadata={\n            \"timestamp\": time.time(),\n            \"type\": \"conversation\"\n        }\n    )\n    \n    return response\n```\n\n### 4. Advanced Features\n\n**Importance Weighting:**\n- Assign importance scores to memories\n- Implement decay functions for temporal relevance\n- Use feedback loops to reinforce useful memories\n\n**Contextual Segmentation:**\n- Organize memories by topics or sessions\n- Create hierarchical memory structures\n- Implement namespace separation for different types of memories\n\n**Memory Consolidation:**\n- Periodically summarize related memories\n- Implement \"sleep\" phases for memory optimization\n- Prune redundant or low-relevance memories\n\n### 5. Performance Optimization\n\n- Implement caching for frequent queries\n- Use batching for embedding generation\n- Consider hybrid approaches (keyword + vector) for faster retrieval\n- Implement pagination for large result sets\n\nWould you like me to elaborate on any specific aspect of this implementation?"
    }
  ]
}
