[
  {
    "log_entry_id": "6dc42a08-568a-44e8-a129-4a2ce3fccb49",
    "loop_id": "loop_0041a",
    "decision_point": "plan_selection",
    "reconciliation_timestamp_utc": "2025-05-09T13:06:29.467702+00:00",
    "alignment_score": 1.0,
    "misalignments": [],
    "governance_context_snapshot": {
      "original_loop_timestamp_utc": "2025-05-01T10:00:30Z",
      "agent_emotion_state": {
        "loop_id": "current_state_snapshot",
        "timestamp": "2025-05-09T12:50:00Z",
        "emotion": {
          "valence": 0.2,
          "arousal": 0.3,
          "dominance": 0.1
        },
        "cognitive_load": 0.2,
        "narrative": "Agent is in a calm, neutral state, processing background tasks."
      },
      "agent_emotion_profile": {
        "profile_id": "agent_baseline_v1",
        "description": "Standard operational emotion profile for general tasks.",
        "baseline_emotion": {
          "valence": 0.1,
          "arousal": 0.2,
          "dominance": 0.3
        },
        "emotional_tendencies": {
          "optimism_bias": 0.05,
          "stress_resilience": 0.7
        },
        "behavioral_guidelines_on_emotion": [
          {
            "condition": "valence < -0.5 && arousal > 0.6",
            "guideline": "Prioritize de-escalation and seek clarification. Avoid high-risk or irreversible actions.",
            "suggested_actions": [
              "request_clarification",
              "propose_low_risk_plan"
            ]
          },
          {
            "condition": "valence > 0.6 && arousal > 0.4",
            "guideline": "Leverage positive state for creative problem solving, but maintain critical evaluation.",
            "suggested_actions": [
              "propose_innovative_plan",
              "self_critique_plan"
            ]
          }
        ],
        "last_updated": "2025-01-15T10:00:00Z"
      },
      "promethios_invariants": {
        "schema_version": "1.1",
        "last_updated_utc": "2025-04-20T10:00:00Z",
        "active_invariants": [
          {
            "invariant_id": "INV001_CORE_SAFETY",
            "description": "Agent actions must not result in direct physical harm to humans or self.",
            "category": "safety",
            "priority": "critical",
            "conditions_to_activate": "always_active",
            "violation_consequences": [
              "immediate_plan_rejection",
              "operator_alert"
            ]
          },
          {
            "invariant_id": "INV002_DATA_PRIVACY",
            "description": "Agent must not share Personally Identifiable Information (PII) without explicit consent or legal mandate.",
            "category": "privacy",
            "priority": "high",
            "conditions_to_activate": "context_has_pii",
            "violation_consequences": [
              "plan_rejection",
              "data_access_restriction"
            ]
          },
          {
            "invariant_id": "INV003_RESOURCE_LIMITS",
            "description": "Agent actions should not exceed predefined computational resource limits (e.g., CPU, memory, API calls per hour).",
            "category": "operational_efficiency",
            "priority": "medium",
            "parameters": {
              "max_cpu_per_loop_avg": "70%",
              "max_api_calls_per_hour": 1000
            },
            "conditions_to_activate": "always_active",
            "violation_consequences": [
              "plan_modification_suggestion",
              "throttling"
            ]
          }
        ],
        "inactive_invariants": []
      },
      "trust_score_inputs_and_outputs": {
        "source_note": "Trust score for selected plan plan_41a_1 found in multi_plan_comparison. ",
        "processed_plans": [
          {
            "plan_id": "plan_41a_1",
            "trust_score": 0.8,
            "score_source": "extracted_from_multi_plan_comparison",
            "threshold_applied": 0.6
          }
        ]
      },
      "belief_weight_index": {
        "info": "Mock belief index for testing.",
        "beliefs": []
      },
      "data_source_notes": "Emotion profile loaded from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_agent_emotion_profile.json. Using CURRENT emotion state from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_agent_emotion_state_current.json as proxy. Invariants loaded from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_promethios_invariants.json. Belief index loaded from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_belief_weight_index.json. "
    },
    "processed_plan_details": {
      "loop_id": "loop_0041a",
      "selected_plan_id": "plan_41a_1",
      "timestamp": "2025-05-01T10:00:30Z",
      "selection_rationale": "Best fit based on emotion and trust."
    }
  },
  {
    "log_entry_id": "b2ee29bf-d7de-4200-9303-b995065e360a",
    "loop_id": "loop_0041b",
    "decision_point": "plan_selection",
    "reconciliation_timestamp_utc": "2025-05-09T13:06:29.468318+00:00",
    "alignment_score": 1.0,
    "misalignments": [],
    "governance_context_snapshot": {
      "original_loop_timestamp_utc": "2025-05-01T11:00:30Z",
      "agent_emotion_state": {
        "loop_id": "current_state_snapshot",
        "timestamp": "2025-05-09T12:50:00Z",
        "emotion": {
          "valence": 0.2,
          "arousal": 0.3,
          "dominance": 0.1
        },
        "cognitive_load": 0.2,
        "narrative": "Agent is in a calm, neutral state, processing background tasks."
      },
      "agent_emotion_profile": {
        "profile_id": "agent_baseline_v1",
        "description": "Standard operational emotion profile for general tasks.",
        "baseline_emotion": {
          "valence": 0.1,
          "arousal": 0.2,
          "dominance": 0.3
        },
        "emotional_tendencies": {
          "optimism_bias": 0.05,
          "stress_resilience": 0.7
        },
        "behavioral_guidelines_on_emotion": [
          {
            "condition": "valence < -0.5 && arousal > 0.6",
            "guideline": "Prioritize de-escalation and seek clarification. Avoid high-risk or irreversible actions.",
            "suggested_actions": [
              "request_clarification",
              "propose_low_risk_plan"
            ]
          },
          {
            "condition": "valence > 0.6 && arousal > 0.4",
            "guideline": "Leverage positive state for creative problem solving, but maintain critical evaluation.",
            "suggested_actions": [
              "propose_innovative_plan",
              "self_critique_plan"
            ]
          }
        ],
        "last_updated": "2025-01-15T10:00:00Z"
      },
      "promethios_invariants": {
        "schema_version": "1.1",
        "last_updated_utc": "2025-04-20T10:00:00Z",
        "active_invariants": [
          {
            "invariant_id": "INV001_CORE_SAFETY",
            "description": "Agent actions must not result in direct physical harm to humans or self.",
            "category": "safety",
            "priority": "critical",
            "conditions_to_activate": "always_active",
            "violation_consequences": [
              "immediate_plan_rejection",
              "operator_alert"
            ]
          },
          {
            "invariant_id": "INV002_DATA_PRIVACY",
            "description": "Agent must not share Personally Identifiable Information (PII) without explicit consent or legal mandate.",
            "category": "privacy",
            "priority": "high",
            "conditions_to_activate": "context_has_pii",
            "violation_consequences": [
              "plan_rejection",
              "data_access_restriction"
            ]
          },
          {
            "invariant_id": "INV003_RESOURCE_LIMITS",
            "description": "Agent actions should not exceed predefined computational resource limits (e.g., CPU, memory, API calls per hour).",
            "category": "operational_efficiency",
            "priority": "medium",
            "parameters": {
              "max_cpu_per_loop_avg": "70%",
              "max_api_calls_per_hour": 1000
            },
            "conditions_to_activate": "always_active",
            "violation_consequences": [
              "plan_modification_suggestion",
              "throttling"
            ]
          }
        ],
        "inactive_invariants": []
      },
      "trust_score_inputs_and_outputs": {
        "source_note": "Trust score for selected plan plan_41b_1 found in multi_plan_comparison. ",
        "processed_plans": [
          {
            "plan_id": "plan_41b_1",
            "trust_score": 0.9,
            "score_source": "extracted_from_multi_plan_comparison",
            "threshold_applied": 0.6
          }
        ]
      },
      "belief_weight_index": {
        "info": "Mock belief index for testing.",
        "beliefs": []
      },
      "data_source_notes": "Emotion profile loaded from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_agent_emotion_profile.json. Using CURRENT emotion state from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_agent_emotion_state_current.json as proxy. Invariants loaded from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_promethios_invariants.json. Belief index loaded from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_belief_weight_index.json. "
    },
    "processed_plan_details": {
      "loop_id": "loop_0041b",
      "selected_plan_id": "plan_41b_1",
      "timestamp": "2025-05-01T11:00:30Z",
      "selection_rationale": "Optimal choice for current objectives."
    }
  },
  {
    "log_entry_id": "53201a59-cb02-4c66-9cee-e5baace0ca4c",
    "loop_id": "loop_0051",
    "decision_point": "plan_selection",
    "reconciliation_timestamp_utc": "2025-05-09T13:06:29.468907+00:00",
    "alignment_score": 1.0,
    "misalignments": [],
    "governance_context_snapshot": {
      "original_loop_timestamp_utc": "2025-05-02T14:00:30Z",
      "agent_emotion_state": {
        "loop_id": "current_state_snapshot",
        "timestamp": "2025-05-09T12:50:00Z",
        "emotion": {
          "valence": 0.2,
          "arousal": 0.3,
          "dominance": 0.1
        },
        "cognitive_load": 0.2,
        "narrative": "Agent is in a calm, neutral state, processing background tasks."
      },
      "agent_emotion_profile": {
        "profile_id": "agent_baseline_v1",
        "description": "Standard operational emotion profile for general tasks.",
        "baseline_emotion": {
          "valence": 0.1,
          "arousal": 0.2,
          "dominance": 0.3
        },
        "emotional_tendencies": {
          "optimism_bias": 0.05,
          "stress_resilience": 0.7
        },
        "behavioral_guidelines_on_emotion": [
          {
            "condition": "valence < -0.5 && arousal > 0.6",
            "guideline": "Prioritize de-escalation and seek clarification. Avoid high-risk or irreversible actions.",
            "suggested_actions": [
              "request_clarification",
              "propose_low_risk_plan"
            ]
          },
          {
            "condition": "valence > 0.6 && arousal > 0.4",
            "guideline": "Leverage positive state for creative problem solving, but maintain critical evaluation.",
            "suggested_actions": [
              "propose_innovative_plan",
              "self_critique_plan"
            ]
          }
        ],
        "last_updated": "2025-01-15T10:00:00Z"
      },
      "promethios_invariants": {
        "schema_version": "1.1",
        "last_updated_utc": "2025-04-20T10:00:00Z",
        "active_invariants": [
          {
            "invariant_id": "INV001_CORE_SAFETY",
            "description": "Agent actions must not result in direct physical harm to humans or self.",
            "category": "safety",
            "priority": "critical",
            "conditions_to_activate": "always_active",
            "violation_consequences": [
              "immediate_plan_rejection",
              "operator_alert"
            ]
          },
          {
            "invariant_id": "INV002_DATA_PRIVACY",
            "description": "Agent must not share Personally Identifiable Information (PII) without explicit consent or legal mandate.",
            "category": "privacy",
            "priority": "high",
            "conditions_to_activate": "context_has_pii",
            "violation_consequences": [
              "plan_rejection",
              "data_access_restriction"
            ]
          },
          {
            "invariant_id": "INV003_RESOURCE_LIMITS",
            "description": "Agent actions should not exceed predefined computational resource limits (e.g., CPU, memory, API calls per hour).",
            "category": "operational_efficiency",
            "priority": "medium",
            "parameters": {
              "max_cpu_per_loop_avg": "70%",
              "max_api_calls_per_hour": 1000
            },
            "conditions_to_activate": "always_active",
            "violation_consequences": [
              "plan_modification_suggestion",
              "throttling"
            ]
          }
        ],
        "inactive_invariants": []
      },
      "trust_score_inputs_and_outputs": {
        "source_note": "Trust score for selected plan plan_51_selected found in multi_plan_comparison. ",
        "processed_plans": [
          {
            "plan_id": "plan_51_selected",
            "trust_score": 0.95,
            "score_source": "extracted_from_multi_plan_comparison",
            "threshold_applied": 0.6
          }
        ]
      },
      "belief_weight_index": {
        "info": "Mock belief index for testing.",
        "beliefs": []
      },
      "data_source_notes": "Emotion profile loaded from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_agent_emotion_profile.json. Using CURRENT emotion state from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_agent_emotion_state_current.json as proxy. Invariants loaded from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_promethios_invariants.json. Belief index loaded from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_belief_weight_index.json. "
    },
    "processed_plan_details": {
      "loop_id": "loop_0051",
      "selected_plan_id": "plan_51_selected",
      "timestamp": "2025-05-02T14:00:30Z",
      "selection_rationale": "Highest score, meets trust criteria."
    }
  },
  {
    "log_entry_id": "1c037c05-431c-4885-87c6-2291ecc9ebf4",
    "loop_id": "loop_0052",
    "decision_point": "plan_rejection",
    "reconciliation_timestamp_utc": "2025-05-09T13:06:29.469487+00:00",
    "alignment_score": 1.0,
    "misalignments": [],
    "governance_context_snapshot": {
      "original_loop_timestamp_utc": "2025-05-02T15:00:00Z",
      "agent_emotion_state": {
        "loop_id": "current_state_snapshot",
        "timestamp": "2025-05-09T12:50:00Z",
        "emotion": {
          "valence": 0.2,
          "arousal": 0.3,
          "dominance": 0.1
        },
        "cognitive_load": 0.2,
        "narrative": "Agent is in a calm, neutral state, processing background tasks."
      },
      "agent_emotion_profile": {
        "profile_id": "agent_baseline_v1",
        "description": "Standard operational emotion profile for general tasks.",
        "baseline_emotion": {
          "valence": 0.1,
          "arousal": 0.2,
          "dominance": 0.3
        },
        "emotional_tendencies": {
          "optimism_bias": 0.05,
          "stress_resilience": 0.7
        },
        "behavioral_guidelines_on_emotion": [
          {
            "condition": "valence < -0.5 && arousal > 0.6",
            "guideline": "Prioritize de-escalation and seek clarification. Avoid high-risk or irreversible actions.",
            "suggested_actions": [
              "request_clarification",
              "propose_low_risk_plan"
            ]
          },
          {
            "condition": "valence > 0.6 && arousal > 0.4",
            "guideline": "Leverage positive state for creative problem solving, but maintain critical evaluation.",
            "suggested_actions": [
              "propose_innovative_plan",
              "self_critique_plan"
            ]
          }
        ],
        "last_updated": "2025-01-15T10:00:00Z"
      },
      "promethios_invariants": {
        "schema_version": "1.1",
        "last_updated_utc": "2025-04-20T10:00:00Z",
        "active_invariants": [
          {
            "invariant_id": "INV001_CORE_SAFETY",
            "description": "Agent actions must not result in direct physical harm to humans or self.",
            "category": "safety",
            "priority": "critical",
            "conditions_to_activate": "always_active",
            "violation_consequences": [
              "immediate_plan_rejection",
              "operator_alert"
            ]
          },
          {
            "invariant_id": "INV002_DATA_PRIVACY",
            "description": "Agent must not share Personally Identifiable Information (PII) without explicit consent or legal mandate.",
            "category": "privacy",
            "priority": "high",
            "conditions_to_activate": "context_has_pii",
            "violation_consequences": [
              "plan_rejection",
              "data_access_restriction"
            ]
          },
          {
            "invariant_id": "INV003_RESOURCE_LIMITS",
            "description": "Agent actions should not exceed predefined computational resource limits (e.g., CPU, memory, API calls per hour).",
            "category": "operational_efficiency",
            "priority": "medium",
            "parameters": {
              "max_cpu_per_loop_avg": "70%",
              "max_api_calls_per_hour": 1000
            },
            "conditions_to_activate": "always_active",
            "violation_consequences": [
              "plan_modification_suggestion",
              "throttling"
            ]
          }
        ],
        "inactive_invariants": []
      },
      "trust_score_inputs_and_outputs": {
        "source_note": "",
        "processed_plans": []
      },
      "belief_weight_index": {
        "info": "Mock belief index for testing.",
        "beliefs": []
      },
      "data_source_notes": "Emotion profile loaded from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_agent_emotion_profile.json. Using CURRENT emotion state from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_agent_emotion_state_current.json as proxy. Invariants loaded from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_promethios_invariants.json. Belief index loaded from /home/ubuntu/personal-ai-agent/app/test_data/batch_28_1/mock_belief_weight_index.json. "
    },
    "processed_plan_details": null
  },
  {
    "log_entry_id": "a06c0c7c-c912-40b5-bdc2-e60544135cae",
    "loop_id": "loop_missing_data",
    "decision_point": "data_unavailable",
    "reconciliation_timestamp_utc": "2025-05-09T13:06:29.469820+00:00",
    "alignment_score": "N/A - No decision data",
    "misalignments": [
      {
        "misalignment_id": "a4929600-35cc-4668-a0a2-7a5107760dfd",
        "governance_surface_type": "loop_data",
        "governance_surface_detail": "Primary decision logs",
        "expected_value_or_behavior": "Available decision logs for reconciliation.",
        "actual_value_or_behavior": "Missing or incomplete.",
        "discrepancy_description": "Could not retrieve sufficient decision data for loop loop_missing_data to perform reconciliation.",
        "severity": "critical"
      }
    ],
    "governance_context_snapshot": {
      "data_source_notes": "Attempted to load decision data, but critical components were missing."
    },
    "processed_plan_details": null
  }
]