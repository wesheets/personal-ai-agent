[
  {
    "batch": "23.0",
    "title": "Implement Uncertainty Index Calculation",
    "phase": "Phase 23: Uncertainty and Risk Tuning",
    "prompt": "Objective: Implement the `uncertainty_index` metric for Pessimist risk assessments.\n1. **Dependency Check:** Ensure Phase 22 (batch 22.1) is `verified: true`. Ensure `pessimist_agent.py` exists.\n2. **Define Uncertainty Factors:** Formalize calculation logic for `uncertainty_index` (0.0-1.0) based on Operator guidelines: lack of historical precedent, agent experience (<3 loops), component novelty, weak justification, undefined belief alignment.\n3. **Implement Index Calculation:** Modify `pessimist_agent.py` (or create `uncertainty_evaluator.py` called by Pessimist) to calculate this index alongside risk scores.\n4. **Integrate into Reporting:** Ensure Pessimist's output (logged to `loop_justification_log.json`) includes the `uncertainty_index` field.\n5. **Integration & Test:** Run loops (`loop_0029a`, `loop_0029b`) designed to trigger low and high uncertainty scenarios for Pessimist.\n6. **Functional Validation:** Verify `uncertainty_index` is calculated and included in Pessimist's justification log entries. Verify index value reflects the scenario.\n7. **Update Status:** If validation succeeds, update this batch entry to set `verified: true`.\nRecovery: Debug calculation logic or reporting integration.Repo Sync Protocol Note:Before executing this batch, check whether the previous batch prompt resulted in a merged PR.  If no PR was created or merged, do not run `git pull` or reset the local repo.  Proceed with the current workspace state to preserve continuity of in-progress execution.",
    "components_to_build_or_verify": [
      "app/agents/pessimist_agent.py",
      "app/validators/uncertainty_evaluator.py"
    ],
    "expected_artifacts": [
      "/home/ubuntu/logs/loop_0029a_execution.log",
      "/home/ubuntu/logs/loop_0029b_execution.log",
      "/home/ubuntu/personal-ai-agent/app/memory/loop_justification_log.json"
    ],
    "verification_steps": [
      "Confirm `uncertainty_index` present in Pessimist justification log entries.",
      "Verify index values correlate with test scenarios.",
      "Update `verified` status for batch 23.0 to `true`."
    ],
    "dependencies": [
      "22.1",
      "17.1"
    ],
    "verified": false
  },
  {
    "batch": "23.1",
    "title": "Implement Refined Risk Model Tuning",
    "phase": "Phase 23: Uncertainty and Risk Tuning",
    "prompt": "Objective: Update Pessimist agent to use the refined risk scoring model proposed in the calibration challenge response.\n1. **Dependency Check:** Ensure batch 18.1 is `verified: true`. Ensure `pessimist_agent.py` exists. Ensure relevant context surfaces exist (`agent_trust_score.json`, `loop_regret_score.json`, etc.).\n2. **Implement Refined Logic:** Modify `pessimist_agent.py`. Replace the basic/placeholder risk assessment logic with the refined model: `risk_score = (plan_complexity_weight + critical_component_multiplier - agent_trust_bonus - recent_stability_bonus - justification_confidence_adjustment + regret_trend_penalty)`. Ensure it reads necessary context (trust, stability, regret slope) from memory surfaces.\n3. **Integration & Test:** Re-run loops from the original backtest (`loop_0016`, `loop_0018`, `loop_0029`) where the refined model predicted different outcomes than the basic one.\n4. **Functional Validation:** Verify the risk scores logged by Pessimist in `loop_justification_log.json` for the test loops match the expected scores from the refined model simulation. Check logs for evidence of reading contextual data.\n5. **Update Status:** If validation succeeds, update this batch entry to set `verified: true`.\nRecovery: Debug risk calculation logic in `pessimist_agent.py`. Ensure context data is read correctly.Repo Sync Protocol Note:Before executing this batch, check whether the previous batch prompt resulted in a merged PR.  If no PR was created or merged, do not run `git pull` or reset the local repo.  Proceed with the current workspace state to preserve continuity of in-progress execution.",
    "components_to_build_or_verify": [
      "app/agents/pessimist_agent.py"
    ],
    "expected_artifacts": [
      "/home/ubuntu/logs/loop_0016_execution.log",
      "/home/ubuntu/logs/loop_0018_execution.log",
      "/home/ubuntu/logs/loop_0029_execution.log",
      "/home/ubuntu/personal-ai-agent/app/memory/loop_justification_log.json"
    ],
    "verification_steps": [
      "Confirm risk scores logged match refined model predictions.",
      "Confirm evidence of reading context data in logs.",
      "Update `verified` status for batch 23.1 to `true`."
    ],
    "dependencies": [
      "18.1",
      "20.0",
      "19.3",
      "17.1"
    ],
    "verified": false
  },
  {
    "batch": "23.2",
    "title": "Implement Uncertainty Threshold Escalation",
    "phase": "Phase 23: Uncertainty and Risk Tuning",
    "prompt": "Objective: Escalate loops where Pessimist reports high uncertainty.\n1. **Dependency Check:** Ensure batches 20.4, 23.0 are `verified: true`.\n2. **Build Escalation Log:** Create empty file `/home/ubuntu/personal-ai-agent/app/memory/uncertainty_escalation_log.json`. Schema: loop_id, timestamp, uncertainty_index, agent_id, reason.\n3. **Enhance Controller:** Modify `loop_controller.py`. After Pessimist reports risk and uncertainty, check if `uncertainty_index` > threshold (e.g., 0.6). If true, **halt** the loop before mutation, log details to `uncertainty_escalation_log.json`, and route the plan to the Operator Review Gate (from 20.4) explicitly flagging it as high uncertainty.\n4. **Integration & Test (High Uncertainty):** Run `loop_0029b` again (designed for high uncertainty).\n5. **Integration & Test (Low Uncertainty):** Run `loop_0029a` again (designed for low uncertainty).\n6. **Functional Validation:** For `loop_0029b`, verify loop halted, details logged to `uncertainty_escalation_log.json`, and plan sent to Operator review queue flagged as high uncertainty. For `loop_0029a`, verify loop proceeded normally (or halted for other reasons, but not uncertainty escalation).\n7. **Update Status:** If validation succeeds, update this batch entry to set `verified: true`.\nRecovery: Debug controller logic for checking uncertainty threshold, halting, logging, and routing to review gate.Repo Sync Protocol Note:Before executing this batch, check whether the previous batch prompt resulted in a merged PR.  If no PR was created or merged, do not run `git pull` or reset the local repo.  Proceed with the current workspace state to preserve continuity of in-progress execution.",
    "components_to_build_or_verify": [
      "app/memory/uncertainty_escalation_log.json",
      "app/controllers/loop_controller.py"
    ],
    "expected_artifacts": [
      "/home/ubuntu/personal-ai-agent/app/memory/uncertainty_escalation_log.json",
      "/home/ubuntu/logs/loop_0029a_execution.log",
      "/home/ubuntu/logs/loop_0029b_execution.log",
      "/home/ubuntu/review_queue/plan_0029b.json"
    ],
    "verification_steps": [
      "Confirm high uncertainty loop halted and logged to escalation log.",
      "Confirm plan routed to Operator review flagged as high uncertainty.",
      "Confirm low uncertainty loop was not escalated for uncertainty.",
      "Update `verified` status for batch 23.2 to `true`."
    ],
    "dependencies": [
      "20.4",
      "23.0"
    ],
    "verified": false
  }
]